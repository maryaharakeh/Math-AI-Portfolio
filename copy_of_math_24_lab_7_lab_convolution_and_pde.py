# -*- coding: utf-8 -*-
"""Copy of Math 24 Lab 7 Lab Convolution and PDE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fu-2Z8XNDwNUZgv8Wgq4hDNTQzAKFiFr

Never Say Never - Documentary on Belousov–Zhabotinsky Reaction BZ

https://www.youtube.com/watch?v=FvXwVZPOoBI


Image Kernels Explained Visually

https://setosa.io/ev/image-kernels/
"""

import numpy as np
from skimage import io as io
import matplotlib.pyplot as plt
from scipy import signal
import torch.nn.functional as F
from torch.nn.functional import *
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import time
from matplotlib import animation, rc
from IPython.display import HTML
rc('animation', html='html5')
#This script is importing several Python libraries and modules that are commonly
#used in image processing, machine learning, and data visualization.

def make_ani(A, colormap='gray'): #This function, make_ani, creates an animation of a 3D array A using matplotlib’s FuncAnimation

    fig, ax = plt.subplots() #This line creates a new figure and a set of subplots. Here, it’s used to create a single subplot.
    im = ax.imshow(A[0,:,:], cmap = colormap); #This line displays the first 2D slice of the 3D array A as an image on the axes. The colormap used is specified by the colormap parameter.
    ax.axis('off') #This line turns off the axis lines and labels.
    fig.set_size_inches(12, 12) #This line sets the figure size to 12x12 inches.

    def animate(data, im):
        im.set_data(data)
#This is a helper function that updates the image data. It’s used in the animation function to update the image at each frame.
    def step():
        for i in range(A.shape[0]):
            data = A[i,:,:]
            yield data
#This is a generator function that yields each 2D slice of the 3D array A. It’s used in the animation function to generate the data for each frame.
    return animation.FuncAnimation(fig, animate, step, interval=100, repeat=True, fargs=(im,))
#This line creates the animation. It uses the animate function to update the
#image at each frame, the step function to generate the data for each frame, and
#it sets the time interval between frames to 100 milliseconds. The animation
#repeats indefinitely. The fargs parameter is used to pass additional arguments
#to the animate function. In this case, the image object im is passed.
#The resulting animation object is returned by the make_ani function.

def plot(x):
    fig, ax = plt.subplots()
    im = ax.imshow(x, cmap = 'gray')
    ax.axis('off')
    fig.set_size_inches(15, 15)
    plt.show()
#The plot(x) function displays the input x as a grayscale image in a 15x15 inch figure with no axis, using matplotlib’s pyplot module.

image = io.imread("https://www.filfre.net/wp-content/uploads/2013/12/bbc4.png")
#converts image to array

image.shape #RGBa

plot(image)

image.shape #returns tuple representing array dimensions giving height, width, and channels

plot(image[:,:,0]) #red channel

plot(image[:,:,1]) #green channel

plot(image[:,:,2]) #blue channel

image.shape

image = np.mean(image, axis=2) #This code calculates the mean across the color channels of an image, effectively converting it to grayscale.

plot(image)

image.shape

a = np.matrix([[1,2,1],[0,0,0],[-1,-2,-1]]) #This code creates a 3x3 matrix representing a simple edge detection filter.

a

plot(a)

image.shape

y = signal.convolve2d(image, a, mode='same')
#This code convolves the image with the edge detection filter "a" using 2D convolution and stores the result in "y".

plot(y)

a = np.transpose(a) #this code flips the rows and columns of the matrix

a

plot(a)

y = signal.convolve2d(image, a, mode='same')
#This code convolves the image with the edge detection filter "a" using 2D convolution and stores the result in "y".

plot(y)

b = np.random.random((25,25)) #This code creates a 25x25 NumPy array filled with random numbers between 0 and 1.

y = signal.convolve2d(image, b) #This code convolves the image with the 25x25 random array "b" using 2D convolution and stores the result in "y".

plot(y)

x = io.imread("https://ichef.bbci.co.uk/news/660/cpsprodpb/C342/production/_88068994_thinkstockphotos-493881770.jpg")
x = x[:,:,0]
#reads image from URL, selects only red channel, then converts to grayscale

x = x.astype(float)
#coverts data type of array to float

x

x = x / 255.0
plot(x)

x #displays array

a #displays array

a[1,1] #element at the second row and second column

def conv2(x,f):
    x2 = np.zeros(x.shape)
    for i in range(1,x.shape[0]-1):
        for j in range(1,x.shape[1]-1):

            x2[i,j] = f[0,0] * x[i-1,j-1]  \
            +         f[0,1] * x[i-1,j]    \
            +         f[0,2] * x[i-1,j+1]  \
            +         f[1,0] * x[i,j-1]    \
            +         f[1,1] * x[i,j]      \
            +         f[1,2] * x[i,j+1]    \
            +         f[2,0] * x[i+1,j-1]  \
            +         f[2,1] * x[i+1,j]    \
            +         f[2,2] * x[i+1,j+1]

    return x2
#This Python function, conv2, performs a 2D convolution operation on the input
#array x using the filter f. It iterates over each element of the array,
#applying the convolution operation using the specified filter coefficients.
#The result is stored in a new array x2, which is then returned.

a = np.matrix([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])
#The variable "a" is assigned a 3x3 matrix representing a basic sharpening filter, with a central coefficient of 8 surrounded by -1 coefficients.

# a = np.matrix([[1,2,1],[0,0,0],[-1,-2,-1]])
# a = np.matrix([[1,1,1],[1,1,1],[1,1,1]])
# a = 5*np.random.random((3,3))-5*np.random.random((3,3))

a #displays matrix

z = conv2(x,a) #performs a 2D convolution operation, to the array "x" using the filter "a", and stores the result in "z".

plot(z)

for i in range(10):
    a = 2*np.random.random((3,3))-1
    print(a)
    z=conv2(x,a)
    plot(z)
#This code iterates 10 times, each time generating a random 3x3 array with values
#between -1 and 1, convolving it with the image array "x" using the conv2
#function, and then plotting the result. This effectively applies random 3x3
#filters to the image and visualizes the output.



#Homemade Conv Loop Timing
a = 2*np.random.random((9,3,3))-1
start_time = time.time()
for i in range(9):

    z=conv2(x,a[i,:,:])

print("Seconds:", (time.time() - start_time))
#This code generates 9 random 3x3 filters stored in a 3D NumPy array "a".
#Then, it measures the time taken to convolve each filter with the image array
# "x" using a loop and the conv2 function. Finally, it prints the elapsed time in seconds.

#Optimized Code Timing
a = 2*np.random.random((9,3,3))-1
start_time = time.time()
for i in range(9):

    z = signal.convolve2d(x,a[i,:,:])

print("--- %s seconds ---" % (time.time() - start_time))
#This code generates 9 random 3x3 filters stored in a 3D NumPy array "a".
#Then, it measures the time taken to convolve each filter with the image array
#"x" using `signal.convolve2d` function from the SciPy library.
#Finally, it prints the elapsed time in seconds.

#GPU Processing Timing, No Loop, 96 filters!!
a2 = 2*np.random.random((96,1,3,3))-1
x2 = torch.tensor(x).cuda()
a2 = torch.tensor(a2).cuda()
x2 = x2[None,None,:,:]

start_time = time.time()
z = conv2d(x2,a2)
print("--- %s seconds ---" % (time.time() - start_time))
#This code seems to be utilizing GPU processing for convolutional operations
#using PyTorch. It generates 96 random 3x3 filters stored in a 4D tensor "a2"
#and converts the image array "x" to a PyTorch tensor, then moves them to the
#GPU memory. After that, it applies the convolution operation using the conv2d
#function without a loop. Finally, it measures and prints the elapsed time in seconds.

z.shape



image = io.imread("https://img.jagranjosh.com/imported/images/E/Articles/Fastest-Fish-img.jpg").astype(float)/255.0
plot(image)

image.shape #gives image array dimensions

plot(np.random.random((11,11,3)))
#This code plots a random 11x11x3 array as an RGB image.

image = np.transpose(image, (2, 0, 1))
#This code transposes the dimensions of the array "image" such that the new dimensions are (3, height, width).

image.shape
#giving dimensions

f = np.random.random((1,3,11,11))
# creates a random 4D array "f" with dimensions, where the first dimension likely represents the number of filters, the second dimension represents the number of input channels, and the last two dimensions represent the filter size

image.shape

image = image[None,:,:,:]
#This code adds a new dimension to the array "image" at the beginning, effectively converting it into a 4D array. The shape of "image" would now be (1, 3, height, width), assuming "height" and "width" represent the dimensions of the image.

image.shape,f.shape
#givess dimensions of both

f =  torch.tensor(f)
image =  torch.tensor(image)
#This code converts NumPy arrays "f" and "image" into PyTorch tensors.

image2 = F.conv2d(image,f)
#This code applies a 2D convolution operation to the input image tensor "image" using the filter tensor "f" with the PyTorch function `F.conv2d`, and stores the result in the tensor "image2".

image2 = image2.numpy() #This code converts the PyTorch tensor "image2" back to a NumPy array.

image2.shape

image2[0,0,:,:].shape
# indicates the dimensions of a specific slice of the tensor "image2". Since the slice represents a single channel of the output image (after convolution), the shape would typically correspond to the height and width of that channel

plot(image2[0,0,:,:])
#This code plots a specific channel of the output image tensor "image2" after convolution.



image = io.imread("http://ian-albert.com/games/super_mario_bros_maps/mario-2-2.gif")
image = image[:,0:700,:]
plot(image)
#reads image from URL and then selects a portion of the image by slicing along the second axis, retaining only the columns up to index 700. Finally, it plots the resulting image.

coin = image[185:200,224:239,:]
#This code selects a specific region of the image, likely representing a coin, by slicing the array "image" along the first and second axes. The selected region spans from row 185 to row 199 (inclusive) and from column 224 to column 238 (inclusive), including all color channels.

plot(coin)

image = image[60:,0:700,:]
plot(image)
#This code updates "image" by cropping the top 60 rows and retaining columns up to index 700, then plots the result.

def scale1(x):
    return (x-np.min(x))/(np.max(x)-np.min(x))
#This function scales the input array "x" to the range [0, 1].

image = np.mean(image,axis=2)
coin = np.mean(coin,axis=2)

image = scale1(image)
coin = scale1(coin)
#These lines convert the image and coin regions to grayscale, then scale their intensity values to the range [0, 1].

plot(image)
plot(coin)

coin.shape

image = image - np.mean(image)
coin = coin - np.mean(coin)
#These lines subtract the mean intensity value from every pixel in the image and coin regions, respectively.

image.shape,coin.shape

coin = np.rot90(coin, 2)
#This code rotates the coin region by 180 degrees, effectively flipping it upside down.

plot(coin)

z = signal.convolve2d(image,coin)
#This code performs a 2D convolution operation between the image and the coin filter using the SciPy `signal.convolve2d` function, and stores the result in "z".

# z = conv2(image,coin)

plot(z)

z == np.max(z)
#This expression checks if every element in the array "z" is equal to the maximum value in "z", resulting in a boolean array indicating whether each element is the maximum value in "z".

plot(z==np.max(z))
#This code plots a binary image where white pixels represent locations where the convolution result "z" equals the maximum value in "z", and black pixels represent other locations.

np.where(z == np.amax(z))
#This code returns the indices of the maximum value in the array "z" using NumPy's `np.where` function.

[y,x] = np.where(z == np.amax(z))
#This code assigns the row indices to "y" and the column indices to "x" where the maximum value in the array "z" occurs, using NumPy's `np.where` function.

plt.plot(x,-y,'.')
#This code plots the points represented by the indices "x" and "y", where the negative of "y" is used to flip the y-axis direction, using dots ('.') as markers.

fig, ax = plt.subplots()
im = ax.imshow(image, cmap = 'gray')
ax.axis('off')
ax.scatter(x-6, y-6, c='red', s=40)
fig.set_size_inches(18, 10)
#This code creates a figure with axes, displays the grayscale image "image" using a grayscale colormap, removes axis labels, and then plots red dots at the coordinates (x-6, y-6) on the image. Finally, it sets the figure size to 18x10 inches.



def conv2(w,f): #GPU conv with padding

    n = conv2d(w.type(torch.int),f.type(torch.int))
    n = pad(n, (1, 1, 1, 1)) #add ones to the sides of the matrix

    return n
#This function `conv2` performs convolution with padding using GPU. It first applies convolution using `conv2d` function, then adds padding to the resulting tensor "n" with ones on all sides.

#Game of Life

w = (np.random.random((100,100)) > 0.5) #game of life world grid w
f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])
#This code generates a 100x100 boolean grid "w" for the Game of Life, where each cell is randomly set to True (alive) or False (dead) based on a probability threshold of 0.5. Additionally, it defines a 3x3 matrix "f" as a filter for the Game of Life rules.

f
#In the Game of Life, this filter is typically used to calculate the next state of a cell based on its neighbors. Specifically, each cell's next state depends on the sum of its surrounding neighbors' states.

plot(w)
#This code plots the Game of Life world grid "w", representing alive cells as white and dead cells as black.

steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.tensor(w.astype(int))[None,None,:,:]
f = torch.tensor(f.astype(int))[None,None,:,:]
#This code sets up variables for simulating the Game of Life. It specifies the number of steps to simulate (`steps`), initializes storage for frames for animation (`A`), converts the boolean grid "w" and the filter "f" to PyTorch tensors, and adds singleton dimensions to make them compatible for convolution operations.

# %%timeit
n = conv2(w,f)
#This code calculates the time it takes to perform the convolution operation between the Game of Life world grid "w" and the filter "f" using the function `conv2`.

# (n==2)[0,0,:,:].shape

plot((n==2)[0,0,:,:]) #This code plots a binary image where white pixels represent locations where the number of neighbors in the convolution result "n" is equal to 2, and black pixels represent other locations.

for i in range(steps):
#This line starts a loop that iterates over the range of steps specified by the variable
    n = conv2(w,f)
#This line calculates the next state of the Game of Life world grid by applying the convolution operation between the current grid w and the filter f, resulting in a new grid n.
    w = (w * (n==2)) + (n==3)
#This line updates the world grid w based on the Game of Life rules: a cell survives if it has exactly 2 neighbors ((n==2)), represented by element-wise multiplication with the current grid w (w * (n==2)), and a cell is born if it has exactly 3 neighbors ((n==3)), represented by addition with the condition (n==3).
    A[i] = w
#This line stores the updated world grid w in the storage array A at the index i, representing the state of the world grid at the current step.

make_ani(A)
#This function creates an animation from the frames stored in the array "A".







#Surface Tension Model

w = (np.random.random((100,100)) > 0.5).astype(int)
f = np.matrix([[1,1,1],[1,1,1],[1,1,1]])
#This code initializes a random 100x100 binary grid "w" and sets up a filter "f" for a surface tension model.

steps = 200
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.tensor(w)[None,None,:,:]
f = torch.tensor(f)[None,None,:,:]
#These lines set up variables for simulating a surface tension model: specifying the number of steps (`steps`), initializing storage for animation frames (`A`), and converting the binary grid "w" and the filter "f" to PyTorch tensors, adding singleton dimensions to make them compatible for convolution operations.

for i in range(steps):
#This line starts a loop that iterates over the range of steps specified by the variable
    n = conv2(w,f)
#This line calculates the convolution of the grid "w" with the filter "f" and stores the result in "n".
    w = ~((n<4) + (n==5))
#This line updates the grid "w" based on the surface tension model rules: cells survive if they have fewer than 4 neighbors and do not have exactly 5 neighbors.
    A[i] = w
#This line stores the updated grid "w" in the storage array "A" at index "i", representing the state of the grid at the current step.

make_ani(A)



#Forest Fire Model

# veg = {empty=0 burning=1 green=2}

Plightning = 0.00005
#This line sets the probability of lightning strikes in the forest fire model to a low value of 0.00005.
Pgrowth = 0.01
#This line sets the probability of tree growth in the forest fire model to 0.01.
w = (np.random.random((100,100)) > 0.5).astype(int)
#This line initializes a random 100x100 binary grid "w", where cells are set to 1 if the random value is greater than 0.5 (representing trees) and 0 otherwise.
f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])
#This line initializes a 3x3 matrix "f" representing a filter for the forest fire model, where the central cell is empty (0) and the surrounding cells represent neighboring trees.
steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
#This line initializes storage for frames for animation, creating a tensor with dimensions (steps, 100, 100) to store the state of the grid at each step.
w = torch.tensor(w)[None,None,:,:]
#This line converts the binary grid "w" to a PyTorch tensor and adds singleton dimensions to make it compatible for convolution operations.
f = torch.tensor(f)[None,None,:,:]
#This line converts the filter "f" to a PyTorch tensor and adds singleton dimensions to make it compatible for convolution operations.

for i in range(steps):

    n = w == 1
#This line initializes a grid "n" where cells are set to True if they contain trees (value 1) in the grid "w", and False otherwise.
    n = conv2(n,f)
#This line calculates the convolution of the grid "n" with the filter "f", resulting in a new grid "n" representing the count of neighboring trees for each cell.
    w =  2*((w == 2)).type(torch.int)                                                \
    -    1*((w == 2) * ( n > 0 ) ).type(torch.int)                                   \
    -    1*((w == 2) * ( np.random.random((100,100)) < Plightning)).type(torch.int)  \
    +    2*((w == 0) * ( np.random.random((100,100)) < Pgrowth)).type(torch.int)

    A[i] = w
#These lines update the forest grid "w" based on the Forest Fire Model rules, incorporating tree survival, ignition, and growth probabilities, and store the updated grid "w" in the storage array "A" at each step for animation.

make_ani(A, colormap='magma')
#This function generates an animation from the frames stored in the array "A", using the "magma" colormap for visualization.



#Nonlinear Waves

w = np.random.random((100,100)) < 0.1
f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])

t  = 6  #center value=6; 7 makes fast pattern; 5 analiating waves
t1 = 3  #center value=3

steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.from_numpy(w)[None,None,:,:]
f = torch.from_numpy(f)[None,None,:,:]
#This code sets up variables for simulating nonlinear waves: initializing a
#random 100x100 grid "w" with a low probability of active cells, defining a
#filter "f" for wave propagation, and specifying parameters for the simulation
#such as the wave center values "t" and "t1", the number of steps, and storage for animation frames.

for i in range(1000):

    n = (w>0)&(w<t)

    n = conv2(n,f)

    w = ((w==0) & (n>=t1)) \
    +  2*(w==1)            \
    +  3*(w==2)            \
    +  4*(w==3)            \
    +  5*(w==4)            \
    +  6*(w==5)            \
    +  7*(w==6)            \
    +  8*(w==7)            \
    +  9*(w==8)            \
    +  0*(w==9)            \

    A[i] = w
#This code iteratively simulates nonlinear wave propagation for 1000 steps, updating the grid "w" based on the presence and intensity of waves and storing each step in an array for animation.

make_ani(A)





#Wireword Wire
#{empty=0 electron_head=1 electron_tail=2, wire=3}

w = np.zeros((100,100))
w[50,:] = 3
w[50,5] = 2
w[50,6] = 1

f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])

steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.from_numpy(w)[None,None,:,:]
f = torch.from_numpy(f)[None,None,:,:]
#The code initializes a wire grid with electrons moving from a specified point using a 3x3 filter, with animation frames stored for visualization.

for i in range(100):

    n=w==1

    n = conv2(n,f)

    w = 1*((w==3)& ((n==1) | (n==2)))                 \
    +   3*((w==3)& ((n!=1) & (n!=2)))                 \
    +   0*(w==0)                    \
    +   2*(w==1)                    \
    +   3*(w==2)                    \

    A[i] = w
#The loop iterates 100 times, updating the wire grid according to cellular automaton rules based on neighboring electron positions, storing each frame for animation.

make_ani(A, colormap='magma')



#Wireworld Oscillator

w = np.zeros((100,100))
w[50,15:-1] = 3
w[48,5:15] = 3
w[52,5:15] = 3
w[49:52,4] = 3
w[49:52,15] = 3
w[52,14] = 1
w[52,13] = 2

f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])

steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.from_numpy(w)[None,None,:,:]
f = torch.from_numpy(f)[None,None,:,:]
#The code initializes a wire grid representing a Wireworld oscillator, with animation frames stored for visualization, and utilizes a 3x3 filter for cellular automaton-based simulation.

for i in range(steps):

    n = w == 1

    n = conv2(n,f)

    w = 0*((w==0))                                    \
    +   2*((w==1))                                    \
    +   3*((w==2))                                    \
    +   3*((w==3)& ((n!=1) & (n!=2)))                 \
    +   1*((w==3)& ((n==1) | (n==2)))                 \

    A[i] = w
#The loop iterates through simulation steps, updating the Wireworld oscillator grid based on cellular automaton rules with neighboring electron positions, storing each frame for animation.

make_ani(A, colormap='magma')





#FitzHugh-Nagumo Reaction Diffusion

def laplacian(U):
    n = conv2d(U,laplace)
    n = pad(n, (1, 1, 1, 1),'circular')
    return n
#The function `laplacian` computes the discrete Laplacian of a 2D array `U` using a predefined laplace filter through convolution and circular padding.

laplace = 0.5*np.array([[0.5, 1.0, 0.5],
                        [1.0, -6., 1.0],
                        [0.5, 1.0, 0.5]])
#The `laplace` variable is a 3x3 numpy array representing a discrete Laplacian filter with central weight -6 and surrounding weights 0.5, used in convolution operations for computing Laplacian in the FitzHugh-Nagumo Reaction Diffusion simulation.

N = 256 #Sets the variable N to 256, representing the dimension of the square grid.
h = 0.05 #Defines the step size or spacing between grid points.

A = np.zeros([N, N], dtype=np.float32)
#Initializes a 2D array A of size N by N with all elements set to 0.0.
A = A + -0.7
#Updates array A by adding -0.7 to all its elements, effectively setting all elements of A to -0.7.
noise_shape = A[:,120:130].shape
# Determines the shape of a subset of A, specifically rows from index 120 to 129 and all columns.
A[:,120:130] = (np.random.normal(0.9,0.05,size=noise_shape))
#Assigns random values drawn from a normal distribution with mean 0.9 and standard deviation 0.05 to the subset of A defined by rows from index 120 to 129 and all columns.
B = np.zeros([N, N], dtype=np.float32)
#Initializes another 2D array B of size N by N with all elements set to 0.0.
B = B + -0.3
#Updates array B by adding -0.3 to all its elements, effectively setting all elements of B to -0.3.

w1 = plot(A)

a0 = -0.1
a1 = 2
epsilon = 0.05
delta = 4
k1 = 1
k2 = 0
k3 = 1
#Defines parameters `a0`, `a1`, `epsilon`, `delta`, `k1`, `k2`, and `k3` for a mathematical model or simulation.

A = torch.from_numpy(A)[None,None,:,:].cuda()
B = torch.from_numpy(B)[None,None,:,:].cuda()
laplace = torch.from_numpy(laplace)[None,None,:,:].type(torch.float).cuda()
#Converts numpy arrays `A` and `B` to PyTorch tensors, and also converts the Laplacian filter `laplace` to a PyTorch tensor, then moves them to GPU memory for computation.

steps = 100
P = torch.zeros((steps,N,N)) # storage for frames for animation
#Initializes a tensor `P` with dimensions `(steps, N, N)` to store frames for animation over 100 steps.

j = 0
for i in range(steps*1000):

    A += h*( k1*A - k2*A**2 - A**3 - B + laplacian(A))
    B += h*( epsilon*(k3*A - a1*B -a0) + delta*laplacian(B) )

    if i % 1000 == 0:
        P[j] = A
        j += 1
#The loop iterates over a large number of time steps, updating the concentrations of substances A and B according to reaction-diffusion equations, storing frames of substance A's concentration every 1000 steps for animation.

make_ani(P)



#Gray Scott Reaction Diffusion

laplace = 0.5*np.array([[0.5, 1.0, 0.5],
                        [1.0, -6., 1.0],
                        [0.5, 1.0, 0.5]])
#Defines a Laplacian filter for use in the Gray-Scott reaction diffusion simulation, with central weight -6 and surrounding weights 0.5.

laplace = torch.from_numpy(laplace)[None,None,:,:].type(torch.float).cuda()
#Converts the Laplacian filter defined as a numpy array to a PyTorch tensor, then moves it to GPU memory for computation.

def laplacian(U):
    n = conv2d(U,laplace)
    n = pad(n, (1,1,1,1))
    n = pad(n, (0,0,0,0))
    return n
#Defines a function `laplacian(U)` to compute the discrete Laplacian of a 2D array `U` using convolution with the laplace filter followed by zero padding.

(Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.065)) # Bacteria 1
# (Du, Dv, F, k) = ((0.14, 0.06, 0.035, 0.065)) # Bacteria 2
# (Du, Dv, F, k) = ((0.16, 0.08, 0.060, 0.062)) # Coral
# (Du, Dv, F, k) = ((0.19, 0.05, 0.060, 0.062)) # Fingerprint
# (Du, Dv, F, k) = ((0.10, 0.10, 0.018, 0.050)) # Spirals
# (Du, Dv, F, k) = ((0.12, 0.08, 0.020, 0.050)) # Spirals Dense
# (Du, Dv, F, k) = ((0.10, 0.16, 0.020, 0.050)) # Spirals Fast
# (Du, Dv, F, k) = ((0.16, 0.08, 0.020, 0.055)) # Unstable
# (Du, Dv, F, k) = ((0.16, 0.08, 0.050, 0.065)) # Worms 1
# (Du, Dv, F, k) = ((0.16, 0.08, 0.054, 0.063)) # Worms 2
# (Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.060)) # Zebrafish

N = 256

U = np.zeros((N,N)) # Clear Chemicals
V = np.zeros((N,N))

U = U + 1.0
r = 5
U[N//2-r:N//2+r,N//2-r:N//2+r] = 0.50 # Add Disturbance in Center Square Radius r
V[N//2-r:N//2+r,N//2-r:N//2+r] = 0.25

U += 0.05*np.random.random((N,N)) # Add Noise to Chemicals
V += 0.05*np.random.random((N,N))

U = torch.from_numpy(U)[None,None,:,:].type(torch.float).cuda()
V = torch.from_numpy(V)[None,None,:,:].type(torch.float).cuda()

steps = 2000
skip = 100
P = torch.zeros((steps,N,N)) # storage for frames for animation
#Sets parameters for the reaction-diffusion simulation representing Bacteria 1, such as diffusion rates (Du and Dv), feed rate F, and kill rate k.
# Initializes 2D arrays U and V representing the concentrations of two chemicals. U represents clear chemicals, and V represents an associated chemical. A disturbance is added in the center of the grid, and noise is introduced to both chemicals.
# Converts numpy arrays U and V to PyTorch tensors and moves them to GPU memory for computation.
#Runs the reaction-diffusion simulation for 2000 steps, storing frames every 100 steps for animation.

j = 0
for i in range(steps*skip):

    U += ( Du*laplacian(U) - U*V**2 +  F   *(1-U) )
#Updates the concentration of chemical U based on diffusion, reaction, and feed rate equations in a Gray-Scott reaction-diffusion model.
    V += ( Dv*laplacian(V) + U*V**2 - (F+k)*V     )
#Updates the concentration of chemical V based on diffusion and reaction equations in a Gray-Scott reaction-diffusion model.
    if i % skip == 0: #Checks if the current iteration is a multiple of the skipping factor.
        P[j] = U # Stores the concentration of chemical U in the storage tensor P at index j.
        j += 1 #Increments the index j for storing frames.

make_ani(P)











# (Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.065)) # Bacteria 1
# (Du, Dv, F, k) = ((0.14, 0.06, 0.035, 0.065)) # Bacteria 2
# (Du, Dv, F, k) = ((0.16, 0.08, 0.060, 0.062)) # Coral
# (Du, Dv, F, k) = ((0.19, 0.05, 0.060, 0.062)) # Fingerprint
# (Du, Dv, F, k) = ((0.10, 0.10, 0.018, 0.050)) # Spirals
# (Du, Dv, F, k) = ((0.12, 0.08, 0.020, 0.050)) # Spirals Dense
# (Du, Dv, F, k) = ((0.10, 0.16, 0.020, 0.050)) # Spirals Fast
# (Du, Dv, F, k) = ((0.16, 0.08, 0.020, 0.055)) # Unstable
# (Du, Dv, F, k) = ((0.16, 0.08, 0.050, 0.065)) # Worms 1
# (Du, Dv, F, k) = ((0.16, 0.08, 0.054, 0.063)) # Worms 2
(Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.060)) # Zebrafish

N = 256

U = np.zeros((N,N)) # Clear Chemicals
V = np.zeros((N,N))

U = U + 1.0
r = 5
U[N//2-r:N//2+r,N//2-r:N//2+r] = 0.50 # Add Disturbance in Center Square Radius r
V[N//2-r:N//2+r,N//2-r:N//2+r] = 0.25

U += 0.05*np.random.random((N,N)) # Add Noise to Chemicals
V += 0.05*np.random.random((N,N))

U = torch.from_numpy(U)[None,None,:,:].type(torch.float).cuda()
V = torch.from_numpy(V)[None,None,:,:].type(torch.float).cuda()

steps = 2000
skip = 100
P = torch.zeros((steps,N,N)) # storage for frames for animation
#This section initializes parameters and grids for a reaction-diffusion
#simulation representing Zebrafish, adds disturbances and noise to the chemical
#concentrations, converts them to PyTorch tensors on the GPU, and sets up storage for animation frames over 2000 steps.

j = 0
for i in range(steps*skip):

    U += ( Du*laplacian(U) - U*V**2 +  F   *(1-U) )
    V += ( Dv*laplacian(V) + U*V**2 - (F+k)*V     )

    if i % skip == 0:
        P[j] = U
        j += 1
#This loop iterates through a large number of simulation steps, updating the concentrations of chemicals U and V according to reaction-diffusion equations in a Zebrafish model. It stores frames of chemical U's concentration every 100 steps for animation.

make_ani(P)









# (Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.065)) # Bacteria 1
# (Du, Dv, F, k) = ((0.14, 0.06, 0.035, 0.065)) # Bacteria 2
(Du, Dv, F, k) = ((0.16, 0.08, 0.060, 0.062)) # Coral
# (Du, Dv, F, k) = ((0.19, 0.05, 0.060, 0.062)) # Fingerprint
# (Du, Dv, F, k) = ((0.10, 0.10, 0.018, 0.050)) # Spirals
# (Du, Dv, F, k) = ((0.12, 0.08, 0.020, 0.050)) # Spirals Dense
# (Du, Dv, F, k) = ((0.10, 0.16, 0.020, 0.050)) # Spirals Fast
# (Du, Dv, F, k) = ((0.16, 0.08, 0.020, 0.055)) # Unstable
# (Du, Dv, F, k) = ((0.16, 0.08, 0.050, 0.065)) # Worms 1
# (Du, Dv, F, k) = ((0.16, 0.08, 0.054, 0.063)) # Worms 2
# (Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.060)) # Zebrafish

N = 256

U = np.zeros((N,N)) # Clear Chemicals
V = np.zeros((N,N))

U = U + 1.0
r = 5
U[N//2-r:N//2+r,N//2-r:N//2+r] = 0.50 # Add Disturbance in Center Square Radius r
V[N//2-r:N//2+r,N//2-r:N//2+r] = 0.25

U += 0.05*np.random.random((N,N)) # Add Noise to Chemicals
V += 0.05*np.random.random((N,N))

U = torch.from_numpy(U)[None,None,:,:].type(torch.float).cuda()
V = torch.from_numpy(V)[None,None,:,:].type(torch.float).cuda()

steps = 8000
skip = 100
P = torch.zeros((steps,N,N)) # storage for frames for animation
#This section initializes parameters and grids for a reaction-diffusion
#simulation representing Coral, adds disturbances and noise to the chemical
#concentrations, converts them to PyTorch tensors on the GPU, and sets up storage for animation frames over 8000 steps.

j = 0
for i in range(steps*skip):

    U += ( Du*laplacian(U) - U*V**2 +  F   *(1-U) )
    V += ( Dv*laplacian(V) + U*V**2 - (F+k)*V     )

    if i % skip == 0:
        P[j] = U
        j += 1
#This loop iterates through a large number of simulation steps, updating the
#concentrations of chemicals U and V according to reaction-diffusion equations in a Coral model.
#It stores frames of chemical U's concentration every 100 steps for animation.

make_ani(P)

